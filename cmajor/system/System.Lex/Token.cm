// =================================
// Copyright (c) 2025 Seppo Laakko
// Distributed under the MIT license
// =================================

using System;
using System.Collections;

namespace System.Lex
{
    public const long CONTINUE_TOKEN = -2;
    public const long INVALID_TOKEN = -1;
    public const long END_TOKEN = 0;

    public class Token
    {
        public Token() : id(INVALID_TOKEN), match(), line(1)
        {
        }
        public Token(long id_) : id(id_), match(), line(1)
        {
        }
        public Token(long id_, const Lexeme& match_, int line_) : id(id_), match(match_), line(line_)
        {
        }
        public inline ustring ToString() const
        {
            return match.ToString();
        }
        public inline uchar Chr() const
        {
            return *match.begin;
        }
        public long id;
        public Lexeme match;
        public int line;
    }

    public bool NoWhiteSpaceBetweenTokens(const Token& first, const Token& second)
    {
        if (first.match.end == second.match.begin) return true;
        return false;
    }

    public ustring GetEndTokenInfo()
    {
        return u"end of file";
    }

    public class TokenLine
    {
        public TokenLine() : tokens(), startState(0), endState(0)
        {
        }
        public int TokenIndex(short columnNumber)
        {
            short col = 1;
            int index = 0;
            for (const Token& token : tokens)
            {
                short len = cast<short>(token.match.end - token.match.begin);
                if (columnNumber >= col && columnNumber < col + len)
                {
                    return index;
                }
                col = col + len;
                ++index;
            }
            return -1;
        }
        public List<Token> tokens;
        public int startState;
        public int endState;
    }

} // namespace System.Lex
